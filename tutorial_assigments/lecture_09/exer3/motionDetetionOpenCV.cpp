#include <iostream>
#include <vector>

// OpenCV Includes
#include <stdio.h>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/calib3d/calib3d.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include "opencv2/imgproc/imgproc_c.h"

#include "opencv2/opencv.hpp"
#include "opencv2/bgsegm.hpp"
#include <opencv2/video/background_segm.hpp>
#include "opencv2/imgcodecs.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
#include "opencv2/bgsegm.hpp"

using namespace cv;
using namespace std;


char keyboard; //input from keyboard



int detectMotion(VideoCapture capture, bool refresh) {
	RNG rng(12345);
	bool changed = false;
	Mat frame;
	if (!capture.isOpened())
		throw "Error when reading steam_avi";
	Mat first_frame;
	Mat frame_Delta;
	Mat thresh;
	Mat changed_frame;
	int dilation_type = MORPH_RECT;
	int dilation_size = 0;
	Mat element = getStructuringElement(dilation_type,
		Size(2 * dilation_size + 1, 2 * dilation_size + 1),
		Point(dilation_size, dilation_size));
	namedWindow("MotionDetetion", 1);
	for (; ; )
	{
		capture >> frame;
		if (frame.empty())
			break;
		//code to analize frame
		cvtColor(frame, changed_frame, CV_BGR2GRAY);
		GaussianBlur(changed_frame, changed_frame, Size(21, 21), 0, 0);
		if (first_frame.empty()) {
			changed_frame.copyTo(first_frame);
		}
		absdiff(first_frame, changed_frame, frame_Delta);
		threshold(frame_Delta, thresh, 25, 255, THRESH_BINARY);

		dilate(thresh, thresh, element);
		vector<Vec4i> hierarchy;
		vector<vector<Point> > contours;
		findContours(thresh, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0));

		vector<vector<Point> > contours_poly(contours.size());
		vector<Rect> boundRect(contours.size());
		vector<Point2f>center(contours.size());
		vector<float>radius(contours.size());

		for (int i = 0; i < contours.size(); i++)
		{
			approxPolyDP(Mat(contours[i]), contours_poly[i], 3, true);
			boundRect[i] = boundingRect(Mat(contours_poly[i]));
			minEnclosingCircle((Mat)contours_poly[i], center[i], radius[i]);
		}

		Mat drawing = Mat::zeros(thresh.size(), CV_8UC3);
		for (int i = 0; i< contours.size(); i++)
		{
			Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
			drawContours(frame, contours_poly, i, color, 1, 8, vector<Vec4i>(), 0, Point());
			rectangle(frame, boundRect[i].tl(), boundRect[i].br(), color, 2, 8, 0);
		}
		if (refresh) {
			if (countNonZero(thresh) < 1) {
				if (!changed) {
					changed_frame.copyTo(first_frame);
					cout << "changed" << endl;
					changed = true;
				}
			}
			else {
				changed = false;
			}

		}

		if (countNonZero(thresh) > 1) {
			putText(frame, "Movement Detected", cvPoint(10, 20), FONT_HERSHEY_SIMPLEX, 0.5, cvScalar(0, 0, 250), 2, CV_AA);
		}

		//imshow("EmotionDetetion", drawing);
		imshow("MotionDetetion", frame);
		//imshow("EmotionDetetion", thresh);
		if (waitKey(30) >= 0) break;
	}
	return 0;
}


/*
int detectMovementwithGMG(string videoFilename) {
	RNG rng(12345);
	//create GUI windows
	namedWindow("MotionDetect");
	// Global variables
	Mat frame; //current frame
	Mat fgMaskGMG; //fg mask fg mask generated by MOG2 method

	Ptr<bgsegm::BackgroundSubtractorGMG> pGMG; //MOG2 Background subtractor

	pGMG = cv::bgsegm::createBackgroundSubtractorGMG(120,0.95); //MOG2 approach

													//create the capture object
	VideoCapture capture(videoFilename);
	if (!capture.isOpened()) {
		//error in opening the video input
		cerr << "Unable to open video file: " << videoFilename << endl;
		exit(EXIT_FAILURE);
	}
	//read input data. ESC or 'q' for quitting
	keyboard = 0;
	while (keyboard != 'q' && keyboard != 27) {
		//read the current frame
		if (!capture.read(frame)) {
			cerr << "Unable to read next frame." << endl;
			cerr << "Exiting..." << endl;
			exit(EXIT_FAILURE);
		}
		//update the background model
		pGMG->apply(frame, fgMaskGMG);
		//get the frame number and write it on the current frame
		stringstream ss;
		rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
			cv::Scalar(255, 255, 255), -1);
		ss << capture.get(CAP_PROP_POS_FRAMES);
		string frameNumberString = ss.str();
		putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
			FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
		//show the current frame and the fg masks


		vector<Vec4i> hierarchy;
		vector<vector<Point> > contours;
		findContours(fgMaskGMG, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0));
		vector<vector<Point> > contours_poly(contours.size());
		vector<Rect> boundRect(contours.size());
		vector<Point2f>center(contours.size());
		vector<float>radius(contours.size());

		for (int i = 0; i < contours.size(); i++)
		{
			approxPolyDP(Mat(contours[i]), contours_poly[i], 3, true);
			boundRect[i] = boundingRect(Mat(contours_poly[i]));
			minEnclosingCircle((Mat)contours_poly[i], center[i], radius[i]);
		}

		Mat drawing = Mat::zeros(fgMaskGMG.size(), CV_8UC3);
		for (int i = 0; i< contours.size(); i++)
		{
			Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
			drawContours(frame, contours_poly, i, color, 1, 8, vector<Vec4i>(), 0, Point());
			rectangle(frame, boundRect[i].tl(), boundRect[i].br(), color, 2, 8, 0);
		}


		if (countNonZero(fgMaskGMG) > 1) {
			putText(frame, "Movement Detected", cvPoint(10, 20), FONT_HERSHEY_SIMPLEX, 0.5, cvScalar(0, 0, 250), 2, CV_AA);
		}

		//imshow("EmotionDetetion", drawing);
		imshow("MotionDetetion", frame);




		//get the input from the keyboard
		keyboard = (char)waitKey(30);
	}
	//delete capture object
	capture.release();
}*/
int detectMovementwithMog2(string videoFilename) {
	RNG rng(12345);
	//create GUI windows
	namedWindow("MotionDetetion");

	// Global variables
	Mat frame; //current frame
	Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
	Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor

	pMOG2 = createBackgroundSubtractorMOG2(500,450,true); //MOG2 approach

											  //create the capture object
	VideoCapture capture(videoFilename);
	if (!capture.isOpened()) {
		//error in opening the video input
		cerr << "Unable to open video file: " << videoFilename << endl;
		exit(EXIT_FAILURE);
	}
	int dilation_type = MORPH_RECT;
	int dilation_size = 0;
	Mat element = getStructuringElement(dilation_type,
		Size(2 * dilation_size + 1, 2 * dilation_size + 1),
	Point(dilation_size, dilation_size));
	//read input data. ESC or 'q' for quitting
	keyboard = 0;
	while (keyboard != 'q' && keyboard != 27) {
		//read the current frame
		if (!capture.read(frame)) {
			cerr << "Unable to read next frame." << endl;
			cerr << "Exiting..." << endl;
			exit(EXIT_FAILURE);
		}
		//update the background model
		pMOG2->apply(frame, fgMaskMOG2);
		//get the frame number and write it on the current frame
		stringstream ss;
		rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
			cv::Scalar(255, 255, 255), -1);
		ss << capture.get(CAP_PROP_POS_FRAMES);
		string frameNumberString = ss.str();
		putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
			FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
		//show the current frame and the fg masks


		vector<Vec4i> hierarchy;
		vector<vector<Point> > contours;
		findContours(fgMaskMOG2, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0));
		vector<vector<Point> > contours_poly(contours.size());
		vector<Rect> boundRect(contours.size());
		vector<Point2f>center(contours.size());
		vector<float>radius(contours.size());

		for (int i = 0; i < contours.size(); i++)
		{
			approxPolyDP(Mat(contours[i]), contours_poly[i], 3, true);
			boundRect[i] = boundingRect(Mat(contours_poly[i]));
			minEnclosingCircle((Mat)contours_poly[i], center[i], radius[i]);
		}

		Mat drawing = Mat::zeros(fgMaskMOG2.size(), CV_8UC3);
		for (int i = 0; i< contours.size(); i++)
		{
			Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
			drawContours(frame, contours_poly, i, color, 1, 8, vector<Vec4i>(), 0, Point());
			rectangle(frame, boundRect[i].tl(), boundRect[i].br(), color, 2, 8, 0);
		}


		if (countNonZero(fgMaskMOG2) > 1) {
			putText(frame, "Movement Detected", cvPoint(10, 20), FONT_HERSHEY_SIMPLEX, 0.5, cvScalar(0, 0, 250), 2, CV_AA);
		}

		//imshow("EmotionDetetion", drawing);
		imshow("MotionDetetion", frame);

		//get the input from the keyboard
		keyboard = (char)waitKey(30);
	}
	//delete capture object
	capture.release();
}
/*
int detectMovementwithMog(string videoFilename) {
	RNG rng(12345);
	//create GUI windows
	namedWindow("MotionDetetion");
	// Global variables
	Mat frame; //current frame
	Mat fgMaskMOG; //fg mask fg mask generated by MOG2 method

	Ptr<bgsegm::BackgroundSubtractorMOG> pMOG; //MOG2 Background subtractor

	pMOG = bgsegm::createBackgroundSubtractorMOG(500, 450, true); //MOG2 approach

													//create the capture object

	VideoCapture capture(videoFilename);
	if (!capture.isOpened()) {
		//error in opening the video input
		cerr << "Unable to open video file: " << videoFilename << endl;
		exit(EXIT_FAILURE);
	}
	int dilation_type = MORPH_RECT;
	int dilation_size = 0;
	Mat element = getStructuringElement(dilation_type,
		Size(2 * dilation_size + 1, 2 * dilation_size + 1),
	Point(dilation_size, dilation_size));

	//read input data. ESC or 'q' for quitting
	keyboard = 0;
	while (keyboard != 'q' && keyboard != 27) {
		//read the current frame
		if (!capture.read(frame)) {
			cerr << "Unable to read next frame." << endl;
			cerr << "Exiting..." << endl;
			exit(EXIT_FAILURE);
		}
		//update the background model
		pMOG->apply(frame, fgMaskMOG);
		//get the frame number and write it on the current frame
		stringstream ss;
		rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
			cv::Scalar(255, 255, 255), -1);
		ss << capture.get(CAP_PROP_POS_FRAMES);
		string frameNumberString = ss.str();
		putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
			FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
		//show the current frame and the fg masks

		vector<Vec4i> hierarchy;
		vector<vector<Point> > contours;
		findContours(fgMaskMOG, contours, hierarchy, CV_RETR_TREE, CV_CHAIN_APPROX_SIMPLE, Point(0, 0));
		vector<vector<Point> > contours_poly(contours.size());
		vector<Rect> boundRect(contours.size());
		vector<Point2f>center(contours.size());
		vector<float>radius(contours.size());

		for (int i = 0; i < contours.size(); i++)
		{
			approxPolyDP(Mat(contours[i]), contours_poly[i], 3, true);
			boundRect[i] = boundingRect(Mat(contours_poly[i]));
			minEnclosingCircle((Mat)contours_poly[i], center[i], radius[i]);
		}

		Mat drawing = Mat::zeros(fgMaskMOG.size(), CV_8UC3);
		for (int i = 0; i< contours.size(); i++)
		{
			Scalar color = Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255));
			drawContours(frame, contours_poly, i, color, 1, 8, vector<Vec4i>(), 0, Point());
			rectangle(frame, boundRect[i].tl(), boundRect[i].br(), color, 2, 8, 0);
		}


		if (countNonZero(fgMaskMOG) > 1) {
			putText(frame, "Movement Detected", cvPoint(10, 20), FONT_HERSHEY_SIMPLEX, 0.5, cvScalar(0, 0, 250), 2, CV_AA);
		}

		//imshow("EmotionDetetion", drawing);
		imshow("MotionDetetion", frame);


		//get the input from the keyboard
		keyboard = (char)waitKey(30);
	}
	//delete capture object
	capture.release();
}
*/
void processVideoMOG2(string videoFilename) {

	//create GUI windows
	namedWindow("Frame");
	namedWindow("FG Mask MOG 2");

	// Global variables
	Mat frame; //current frame
	Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
	Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor

	pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach

	//create the capture object
	VideoCapture capture(videoFilename);
	if (!capture.isOpened()) {
		//error in opening the video input
		cerr << "Unable to open video file: " << videoFilename << endl;
		exit(EXIT_FAILURE);
	}
	//read input data. ESC or 'q' for quitting
	keyboard = 0;
	while (keyboard != 'q' && keyboard != 27) {
		//read the current frame
		if (!capture.read(frame)) {
			cerr << "Unable to read next frame." << endl;
			cerr << "Exiting..." << endl;
			exit(EXIT_FAILURE);
		}
		//update the background model
		pMOG2->apply(frame, fgMaskMOG2);
		//get the frame number and write it on the current frame
		stringstream ss;
		rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
			cv::Scalar(255, 255, 255), -1);
		ss << capture.get(CAP_PROP_POS_FRAMES);
		string frameNumberString = ss.str();
		putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
			FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
		//show the current frame and the fg masks
		imshow("Frame", frame);
		imshow("FG Mask MOG 2", fgMaskMOG2);
		//get the input from the keyboard
		keyboard = (char)waitKey(30);
	}
	//delete capture object
	capture.release();
}
/*
void processVideoMOG(string videoFilename) {

	//create GUI windows
	namedWindow("Frame");
	namedWindow("FG Mask MOG");

	// Global variables
	Mat frame; //current frame
	Mat fgMaskMOG; //fg mask fg mask generated by MOG2 method

	Ptr<bgsegm::BackgroundSubtractorMOG> pMOG; //MOG2 Background subtractor

	pMOG = bgsegm::createBackgroundSubtractorMOG(); //MOG2 approach

											  //create the capture object
	VideoCapture capture(videoFilename);
	if (!capture.isOpened()) {
		//error in opening the video input
		cerr << "Unable to open video file: " << videoFilename << endl;
		exit(EXIT_FAILURE);
	}
	//read input data. ESC or 'q' for quitting
	keyboard = 0;
	while (keyboard != 'q' && keyboard != 27) {
		//read the current frame
		if (!capture.read(frame)) {
			cerr << "Unable to read next frame." << endl;
			cerr << "Exiting..." << endl;
			exit(EXIT_FAILURE);
		}
		//update the background model
		pMOG->apply(frame, fgMaskMOG);
		//get the frame number and write it on the current frame
		stringstream ss;
		rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
			cv::Scalar(255, 255, 255), -1);
		ss << capture.get(CAP_PROP_POS_FRAMES);
		string frameNumberString = ss.str();
		putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
			FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
		//show the current frame and the fg masks
		imshow("Frame", frame);
		imshow("FG Mask MOG", fgMaskMOG);
		//get the input from the keyboard
		keyboard = (char)waitKey(30);
	}
	//delete capture object
	capture.release();
}
*/
/*
void processVideoGMG(string videoFilename) {

	//create GUI windows
	namedWindow("Frame");
	namedWindow("FG Mask GMG");

	// Global variables
	Mat frame; //current frame
	Mat fgMaskGMG; //fg mask fg mask generated by MOG2 method

	Ptr<bgsegm::BackgroundSubtractorGMG> pGMG; //MOG2 Background subtractor

	pGMG = bgsegm::createBackgroundSubtractorGMG(); //MOG2 approach

													//create the capture object
	VideoCapture capture(videoFilename);
	if (!capture.isOpened()) {
		//error in opening the video input
		cerr << "Unable to open video file: " << videoFilename << endl;
		exit(EXIT_FAILURE);
	}
	//read input data. ESC or 'q' for quitting
	keyboard = 0;
	while (keyboard != 'q' && keyboard != 27) {
		//read the current frame
		if (!capture.read(frame)) {
			cerr << "Unable to read next frame." << endl;
			cerr << "Exiting..." << endl;
			exit(EXIT_FAILURE);
		}
		//update the background model
		pGMG->apply(frame, fgMaskGMG);
		//get the frame number and write it on the current frame
		stringstream ss;
		rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
			cv::Scalar(255, 255, 255), -1);
		ss << capture.get(CAP_PROP_POS_FRAMES);
		string frameNumberString = ss.str();
		putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
			FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
		//show the current frame and the fg masks
		imshow("Frame", frame);
		imshow("FG Mask GMG", fgMaskGMG);
		//get the input from the keyboard
		keyboard = (char)waitKey(30);
	}
	//delete capture object
	capture.release();
}*/
int subtration_algorithm(VideoCapture capture) {
	Mat frame;
	if (!capture.isOpened())
		throw "Error when reading steam_avi";
	Mat first_frame;
	Mat frame_Delta;
	Mat thresh;
	Mat changed_frame;
	int dilation_type = MORPH_RECT;
	int dilation_size = 0;
	Mat element = getStructuringElement(dilation_type,
		Size(2 * dilation_size + 1, 2 * dilation_size + 1),
		Point(dilation_size, dilation_size));
	namedWindow("MotionDetetion", 1);
	namedWindow("Subtration", 1);

	for (; ; )
	{
		capture >> frame;
		if (frame.empty())
			break;
		//code to analize frame
		cvtColor(frame, changed_frame, CV_RGB2GRAY);
		GaussianBlur(changed_frame, changed_frame, Size(21, 21), 0, 0);
		if (first_frame.empty()) {
			changed_frame.copyTo(first_frame);
		}
		absdiff(first_frame, changed_frame, frame_Delta);
		threshold(frame_Delta, thresh, 25, 255, THRESH_BINARY);

		dilate(thresh, thresh, element);


		//imshow("EmotionDetetion", drawing);
		imshow("MotionDetetion", frame);
		imshow("Subtration",thresh);
		//imshow("EmotionDetetion", thresh);
		if (waitKey(30) >= 0) break;
	}
	return 0;
}

int captureVideo() {
	VideoCapture cap(0); // open the default camera
	detectMotion(cap,true);
	// the camera will be deinitialized automatically in VideoCapture destructor
	return 0;
}

int readVideoFile(string videoFilename) {
	VideoCapture capture(videoFilename);
	detectMotion(capture,true);
	waitKey(0); // key press to close window
				// releases and window destroy are automatic in C++ interface
	return 0;
}

int processVideoSub(string videoFilename) {
	VideoCapture capture(videoFilename);
	subtration_algorithm(capture);
	waitKey(0); // key press to close window
				// releases and window destroy are automatic in C++ interface
	return 0;
}

void printMenu() {
	cout << "Options:\n";
	cout << "3- Detect Motion with  With (MOG)	\n";
	cout << "4- Detect Motion with  With (MOG2)	\n";
	cout << "5- Detect Motion with (GMG) 	\n";
	cout << "6- Analyze subtration with algorithm used to detect motion	\n";
	cout << "7- Analyze subtration With (MOG) \n";
	cout << "8- Analyze subtration With (MOG2) \n";
	cout << "9- Analyze subtration (GMG) \n";
	cout << "0- End Program\n" << endl;

}
void selectOption(int optionChoose) {
	switch (optionChoose)
	{
	case 3:
		//etectMovementwithMog(userInput);
		break;
	case 4:
		detectMovementwithMog2("video1.mp4");
		break;
	case 5:
		//detectMovementwithGMG(userInput);
		break;
	case 6:
		processVideoSub("video1.mp4");
		break;
	case 7:
	//	processVideoMOG(userInput);
		break;
	case 8:
		processVideoMOG2("video1.mp4");
		break;
	case 9:
	//	processVideoGMG(userInput);
		break;
	default:
		break;
	}
}
int main(int, char**)
{
	string userInput;
	int optionChoose = 0;
	do {
		printMenu();
		getline(cin, userInput);
		optionChoose = stoi(userInput);
		selectOption(optionChoose);
	} while (optionChoose != 0);

	destroyAllWindows();
	return 0;

}
